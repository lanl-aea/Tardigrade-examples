#! /usr/bin/env python

""" Workflow for running and multi domain upscaling of an Abaqus/Standard dynamic DNS of an elastic cylinder under uni-axial stress in compression
Requires the following ``Sconscript(..., exports=[])``
* ``env`` - The SCons construction environment with the following required keys
  * ``Tardigrade_MOOSE_source_abspath`` - String absolute path to model_package/Tardigrade-MOOSE
  * ``cubit`` - String absolute path to Cubit Python intepreter, optional
  * ``selected_parameter_sets`` - Optional string of space separated integers specifying which parameters sets should be considered for filtering, calibrating, and performing macroscale simulations
  * ``filter`` - Boolean speciyfing whether or not to run micromorphic filter for a particular upscaling study
  * ``macro`` - Boolean speciyfing whether or not to run macro simulation(s) in Tardigrade-MOOSE
  * ``summary`` - Boolean speciyfing whether or not to run summary post-processing for multi-domain studies
"""

import copy
import pathlib

import waves
import numpy

from model_package.DNS_Abaqus import simulation_variables_nominal


# Inherit the parent construction environment
Import('env')

# set project-wide paths with os-agnostic path separators
Tardigrade_MOOSE_source_abspath = pathlib.Path(env["Tardigrade_MOOSE_source_abspath"])

# Simulation variables
build_directory = pathlib.Path(Dir('.').abspath)
workflow_name = build_directory.name
output_file_type = "h5"
model = "axisymmetric_wave_study"
default_params = simulation_variables_nominal.axisymmetric_wave_study

# Collect the target nodes to build a concise alias for all targets
workflow = []

# ---------- MULTI-DOMAIN ------------------------------------------------------
# setup several options for different studies
parameter_schema = dict(
    parameter_samples = numpy.array([
        [0., "y", "at_surface_y_load"],
        [1., "y", "depth_1_y_load"],
        [2.5, "y", "depth_2_y_load"],
        [5.0, "y", "depth_3_y_load"],
        [0., "x", "at_surface_x_load"],
        [1., "x", "depth_1_x_load"],
        [2.5, "x", "depth_2_x_load"],
        [5.0, "x", "depth_3_x_load"],
        ], dtype=object),
    parameter_names = numpy.array(["source_depth", "load_direction", "study_name"])
)

parameter_generator = waves.parameter_generators.CustomStudy(parameter_schema)
for set_name, parameters in parameter_generator.parameter_study_to_dict().items():

    set_name = pathlib.Path(set_name)

    source_depth = parameters['source_depth']
    load_direction = parameters['load_direction']
    study_name = parameters['study_name']

    params = copy.deepcopy(default_params)
    params['model_name'] = f'{model}_{study_name}'
    params['job_name'] = f'{model}_{study_name}_job'
    params['source_depth'] = source_depth
    params['load_direction'] = load_direction

    # Run common sconscript
    variant_dir = build_directory / set_name
    workflow.extend(
        SConscript("Abaqus_dynamic_axisymmetric_point_source.scons", variant_dir=variant_dir,
                exports=["env", "workflow_name", "model", "params"],
                duplicate=False))

# ---------- Collect Results across Studies ------------------------------------
# # Run common post-processing sconscript
# if env['summary']:
#     study = parameter_generator.parameter_study_to_dict()
#     set_names = [pathlib.Path(set_name) for set_name, _ in study.items()]
#     num_domains = [str(study[key]['num_domains']) for key in study.keys()]
#     dns_forces = f"DNS_{model}_run_force_displacement.csv"

#     workflow.extend(
#         SConscript("summarize_multi_domain.scons",
#                    exports=["env", "workflow_name", "model", "params", "set_names", "num_domains", "dns_forces"],
#                    duplicate=False))

# Collector alias based on parent directory name
env.Alias(workflow_name, workflow)
