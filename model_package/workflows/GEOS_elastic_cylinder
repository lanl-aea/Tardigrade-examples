#! /usr/bin/env python

""" TODO

"""

import pathlib
import os

import waves
import numpy
import SCons.Defaults
import pandas
import yaml

from model_package.DNS_GEOS import simulation_variables_nominal

# Inherit the parent construction environment
Import('env')

# set project-wide paths with os-agnostic path separators
DNS_GEOS_abspath = pathlib.Path(env["DNS_GEOS_abspath"])
filter_source_abspath = pathlib.Path(env["filter_source_abspath"])
calibrate_source_abspath = pathlib.Path(env["calibrate_source_abspath"])
Tardigrade_MOOSE_source_abspath = pathlib.Path(env["Tardigrade_MOOSE_source_abspath"])
model_package_abspath = pathlib.Path(env["model_package_abspath"])
peta_data_copy_abspath = pathlib.Path(env["peta_data_copy_abspath"])

# Simulation variables
build_directory = pathlib.Path(Dir('.').abspath)
workflow_name = build_directory.name
workflow_configuration = [env["project_configuration"], workflow_name]
output_file_type = "h5"
model = "GEOS_elastic_cylinder"
params = simulation_variables_nominal.elastic_cylinder

# Collect the target nodes to build a concise alias for all targets
workflow = []

# specify targets for visualizing Micromorphic Filter output
viz_targs =  (
    ('plot-stress-norms', 'stress_norms.png'),
    ('plot-better-stress-norms', 'better_stress_norms.png'),
    ('plot-best-stress-norms', 'best_stress_norms.png'),
    ('plot-norm-histories', 'norm_histories.png'),
    ('p-q-plots', 'p_q_plots.png'),
    ('csv-cauchy', 'cauchy.csv'),
    ('csv-PK2', 'PK2.csv'),
    ('csv-GLstrain', 'GLstrain.csv'),
    ('csv-estrain', 'estrain.csv'),
    ('csv-ref-mod', 'ref_moduli.csv'),
    ('csv-cur-mod', 'cur_moduli.csv'),
    ('csv-symm', 'symm.csv'),
    ('csv-stress-diff', 'stress_diff.csv'),
    ('csv-m', 'm_stress.csv'),
    ('csv-M', 'M_stress.csv'),
    ('csv-stress33-all', 'all_33_stresses.csv'),
    )
params['viz_targs'] = viz_targs

# ---------- Process existing DNS ----------------------------------------------
DNS_fileroot = params['DNS_fileroot']
results_file = params['DNS_file']

# Filter prep - Extract results to XDMF
main_XDMF_name = f"FILTER_INPUT_{model}"
filter_inputs = [f"{main_XDMF_name}.{ext}" for ext in ['xdmf', 'h5']]
cauchy_stresses = "DNS_all_33_stresses.csv"
XDMF_script = "vtk_to_xdmf.py"
script_options = f"--input-file {results_file}"
script_options += f" --file-root {DNS_fileroot}"
script_options += f" --output-file {str(build_directory / main_XDMF_name)}"
script_options += " --dist-factor 0.001"
script_options += " --stress-factor 1."
script_options += " --density-factor 1.e-12"
workflow.extend(env.PythonScript(
    target=filter_inputs + [cauchy_stresses],
    source=[str(DNS_GEOS_abspath / XDMF_script), f'{DNS_fileroot}/{results_file}'],
    script_options=script_options))

# Get bounding information from DNS extents
bounding_csv = f"{model}_bounds.csv"
bounding_script = "bounds_from_DNS.py"
script_options = f"--dns-file {filter_inputs[0]}"
script_options += f" --output-file {bounding_csv}"
workflow.extend(env.PythonScript(
    target=bounding_csv,
    source=[str(filter_source_abspath / bounding_script)] + filter_inputs,
    script_options=script_options))

# TODO: bounds from background grid are larger than material points, figure out how to force the correct sized cylinder
rad = 0.5*params['diam']
bounding_csv = f"{model}_forced_bounds.csv"
bounding_script = "force_bounds.py"
script_options = f"--output-file {bounding_csv}"
script_options += f" --xmin {-1*rad} --xmax {rad} --ymin {-1*rad} --ymax {rad} --zmin 0 --zmax{params['height']}"
workflow.extend(env.PythonScript(
    target=bounding_csv,
    source=[str(filter_source_abspath / bounding_script)],
    script_options=script_options))

params['bounding_csv'] = str(build_directory / bounding_csv)
filter_inputs = [f"{str(build_directory / main_XDMF_name)}.{ext}" for ext in ['xdmf', 'h5']]

# # Post-processing step - force vs. displacement
# plot_script = "plot_force_displacement.py"
# force_results = f"{peta_data_copy_abspath}/{params['DNS_forces']}"
# force_plot_targets = [f"{model}_force_displacement.png", f"{model}_force_displacement.csv"]
# script_options = f"--csv-file {force_results}"
# script_options += f" --output-file {force_plot_targets[0]}"
# script_options += f" --output-csv {force_plot_targets[1]}"
# script_options += " --force-col 'Force (N)'"
# script_options += " --header-row 0"
# script_options += " --filter-markers 0 10 15 20 25 30 35 40 45 50 55 60 70 80"
# workflow.extend(env.PythonScript(
    # target=[force_plot_targets],
    # source=[str(DNS_Ratel_abspath / plot_script)],
    # script_options=script_options,
    # ))

# # # Get image of DNS results
# # paraview_script= "get_paraview_image.py"
# # paraview_image = f"{model}_Cauchy.png"
# # script_options = f"--input-file {results_files[-1]}"
# # script_options += f" --output-file {paraview_image}"
# # script_options += " --field diagnostic_quantitiesprojected.Cauchy_stress_zz"
# # script_options += " --field-min -10.0 --field-max 0.0"
# # script_options += " --legend-title 'Cauchy Stress 33 (MPa)'"
# # workflow.extend(env.ParaviewImage(
    # # target=paraview_image,
    # # source=[str(model_package_abspath / paraview_script)] + results_files,
    # # script=str(model_package_abspath / paraview_script),
    # # script_options=script_options))

# ---------- FILTER ------------------------------------------------------------
parameters = {'seed_size': params['height'],
              'num_domains': 1,}
filter_results = f"FILTER_RESULTS_{model}_1"
filter_targs = [f"{filter_results}.{ext}" for ext in ['xdmf', 'h5']]
params['filter_targs'] = filter_targs
# Run common filter sconscript
if env['filter']:
    workflow.extend(
        SConscript("filter.scons",
                   exports=["env", "parameters", "workflow_name", "model", "params", "filter_inputs"],
                   duplicate=False))

# ---------- CALIBRATE ---------------------------------------------------------
# Run common calibration sconscript
case = params['calibration_case']
if env['calibrate']:
    filter_file = str(build_directory / filter_targs[0])
    params['filter_file'] = filter_file
    workflow.extend(
        SConscript("calibrate_element.scons",
                   exports=["env", "parameters", "workflow_name", "model", "params"],
                   duplicate=False))
params['parameter_sets'] = [f'calibrated_parameters_case_{case}_elem_0.yml']

# ---------- Tardigrade-MOOSE --------------------------------------------------
# Run common Tardigrade-MOOSE sconscript
if env['macro']:
    workflow.extend(
        SConscript("tardigrade_moose.scons",
                   exports=["env", "parameters", "workflow_name", "model", "params"],
                   duplicate=False))

# ---------- ARCHIVE -----------------------------------------------------------
# Archive
archive_DNS = True
if archive_DNS:
    archive_name = f"{env['project_name']}-{env['version']}"
    archive_target = env.Tar(
        target=archive_name,
        source=workflow + workflow_configuration)

# Collector alias based on parent directory name
env.Alias(workflow_name, workflow)
env.Alias(f"{workflow_name}_archive", archive_target)