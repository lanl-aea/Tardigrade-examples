#! /usr/bin/env python

""" Workflow for multi domain upscaling of a GEOS MPM DNS of an elastic cylinder under uni-axial stress in compression
Requires the following ``Sconscript(..., exports=[])``
* ``env`` - The SCons construction environment with the following required keys
  * ``DNS_GEOS_abspath`` - String absolute path to model_package/DNS_GEOS
  * ``filter_source_abspath`` - String absolute path to model_package/Filter
  * ``model_package_abspath`` - String absolute path to model_package
  * ``peta_data_copy_abspath`` - String absolute path to peta_data_copy
  * ``cubit`` - String absolute path to Cubit Python intepreter, optional
  * ``selected_parameter_sets`` - Optional string of space separated integers specifying which parameters sets should be considered for filtering, calibrating, and performing macroscale simulations
  * ``filter`` - Boolean speciyfing whether or not to run micromorphic filter for a particular upscaling study
  * ``calibrate`` - Boolean speciyfing whether or not to run calibration for a particular upscaling study
  * ``macro`` - Boolean speciyfing whether or not to run macro simulation(s) in Tardigrade-MOOSE
"""

import pathlib

import waves
import numpy

from model_package.DNS_GEOS import simulation_variables_nominal


# Inherit the parent construction environment
Import('env')

# set project-wide paths with os-agnostic path separators
DNS_GEOS_abspath = pathlib.Path(env["DNS_GEOS_abspath"])
filter_source_abspath = pathlib.Path(env["filter_source_abspath"])
model_package_abspath = pathlib.Path(env["model_package_abspath"])
peta_data_copy_abspath = pathlib.Path(env["peta_data_copy_abspath"])

# Simulation variables
build_directory = pathlib.Path(Dir('.').abspath)
workflow_name = build_directory.name
output_file_type = "h5"
model = "GEOS_I43_01_sim38"
params = simulation_variables_nominal.I43_01_sim38

# Collect the target nodes to build a concise alias for all targets
workflow = []

# specify targets for visualizing Micromorphic Filter output
viz_targs =  (
    ('plot-cauchy-couple', 'cauchy_couple.png'),
    ('plot-stress-norms', 'stress_norms.png'),
    ('plot-better-stress-norms', 'better_stress_norms.png'),
    ('plot-best-stress-norms', 'best_stress_norms.png'),
    ('plot-norm-histories', 'norm_histories.png'),
    ('p-q-plots', 'p_q_plots.png'),
    ('csv-cauchy', 'cauchy.csv'),
    ('csv-PK2', 'PK2.csv'),
    ('csv-GLstrain', 'GLstrain.csv'),
    ('csv-estrain', 'estrain.csv'),
    ('csv-ref-mod', 'ref_moduli.csv'),
    ('csv-cur-mod', 'cur_moduli.csv'),
    ('csv-symm', 'symm.csv'),
    ('csv-stress-diff', 'stress_diff.csv'),
    ('csv-m', 'm_stress.csv'),
    ('csv-M', 'M_stress.csv'),
    ('csv-stress33-all', 'all_33_stresses.csv'),
    ('plot-stress-diff', 'stress_diff.png'),
    ('plot-rotation-diff', 'rotation_diff.png'),
    ('plot-stretch-diff', 'stretch_diff.png'),
    )
params['viz_targs'] = viz_targs

# ---------- Process existing DNS ----------------------------------------------
DNS_fileroot = f"{peta_data_copy_abspath}/{params['DNS_fileroot']}"
results_file = params['DNS_file']

# TODO: remove background grid data before filter prep

# Filter prep - Extract results to XDMF
main_XDMF_name = f"FILTER_INPUT_{model}"
filter_inputs = [f"{main_XDMF_name}.{ext}" for ext in ['xdmf', 'h5']]
cauchy_stresses = "DNS_all_33_stresses.csv"
XDMF_script = "vtk_to_xdmf_fast_multi.py"
script_options = f"--input-file {results_file}"
script_options += f" --file-root {DNS_fileroot}"
script_options += f" --output-file {str(build_directory / main_XDMF_name)}"
script_options += " --dist-factor 1"
script_options += " --stress-factor 1000."
script_options += " --density-factor 1.e-9"
script_options += " --num-ranks 216"
script_options += " --upscale-damage True"
script_options += " --grain-particle-key 0 --binder-particle-key 1"
workflow.extend(env.PythonScript(
    target=filter_inputs,
    source=[str(DNS_GEOS_abspath / XDMF_script), f'{DNS_fileroot}/{results_file}'],
    script_options=script_options))
#params['homogenize_damage'] = True

# Get bounding information from DNS extents
bounding_csv = f"{model}_bounds.csv"
bounding_script = "bounds_from_DNS.py"
script_options = f"--dns-file {filter_inputs[0]}"
script_options += f" --output-file {bounding_csv}"
workflow.extend(env.PythonScript(
    target=bounding_csv,
    source=[str(filter_source_abspath / bounding_script)] + filter_inputs,
    script_options=script_options))

# TODO: bounds from background grid are larger than material points, figure out how to force the correct sized cylinder
rad = 0.5*params['diam']
bounding_csv = f"{model}_forced_bounds.csv"
bounding_script = "force_bounds.py"
script_options = f"--output-file {bounding_csv}"
#script_options += f" --xmin {-1*rad} --xmax {rad} --ymin {-1*rad} --ymax {rad} --zmin 0 --zmax {params['height']}"
xmin, xmax = -2.6692708333333335,2.3654513888888884
ymin, ymax = -2.6692708333333335,2.3654513888888884
zmin = 0.6473214285714286 - 0.03125 
zmax = 5.200892857142858 + 0.03125
script_options += f" --xmin {xmin} --xmax {xmax} --ymin {ymin} --ymax {ymax} --zmin {zmin} --zmax {zmax}"
workflow.extend(env.PythonScript(
    target=bounding_csv,
    source=[str(filter_source_abspath / bounding_script)],
    script_options=script_options))

params['bounding_csv'] = str(build_directory / bounding_csv)
filter_inputs = [f"{str(build_directory / main_XDMF_name)}.{ext}" for ext in ['xdmf', 'h5']]

# Post-processing step - force vs. displacement
plot_script = "plot_force_displacement.py"
force_results = f"{DNS_fileroot}/{params['DNS_forces']}"
force_plot_targets = [f"{model}_force_displacement.png", f"{model}_force_displacement.csv"]
script_options = f"--csv-file {force_results}"
script_options += f" --output-file {force_plot_targets[0]}"
script_options += f" --output-csv {force_plot_targets[1]}"
script_options += " --force-col ' Rz+'"
script_options += " --length-col ' length_z'"
script_options += " --header-row 0"
script_options += " --force-factor -1000 --disp-factor -1"
script_options += " --filter-markers 0 494 751 1009 1244 1501 1759 1994 2187 2487 2594"
workflow.extend(env.PythonScript(
    target=[force_plot_targets],
    source=[str(DNS_GEOS_abspath / plot_script)],
    script_options=script_options,
    ))

# # # Get image of DNS results
# # paraview_script= "get_paraview_image.py"
# # paraview_image = f"{model}_Cauchy.png"
# # script_options = f"--input-file {results_files[-1]}"
# # script_options += f" --output-file {paraview_image}"
# # script_options += " --field diagnostic_quantitiesprojected.Cauchy_stress_zz"
# # script_options += " --field-min -10.0 --field-max 0.0"
# # script_options += " --legend-title 'Cauchy Stress 33 (MPa)'"
# # workflow.extend(env.ParaviewImage(
    # # target=paraview_image,
    # # source=[str(model_package_abspath / paraview_script)] + results_files,
    # # script=str(model_package_abspath / paraview_script),
    # # script_options=script_options))

# ---------- MULTI-DOMAIN ------------------------------------------------------
# setup several options for different studies
if params['cut'] == False:
    if 'cubit' not in env.keys():
        raise NotImplementedError("Without access to Cubit, this workflow can not be completed!")
    parameter_schema = dict(
        parameter_samples = numpy.array([
            [5.0, 1],
            [2.5, 4],
            [1.5, 42],
            #[1.0, 128],
            [0.75, 282],
            [0.5, 837],
            [0.375, 1908],
            [0.25, 6480],
            #[0.1, 105600],
            ], dtype=object),
        parameter_names = numpy.array(["seed_size", "num_domains"])
    )
elif params['cut'] == True:
    parameter_schema = dict(
        parameter_samples = numpy.array([
            [5.0, 1],
            [2.5, 24],
            [1.5, 48],
            #[1.0, 128],
            [0.75, 264],
            [0.55, 768],
            [0.4, 1680],
            [0.25, 6912],
            #[0.1, 110400],
            ], dtype=object),
        parameter_names = numpy.array(["seed_size", "num_domains"])
    )
else:
    print('Specify valid option!')

parameter_flag = False
if env['selected_parameter_sets'] != "All":
    parameter_flag = True
    selected_parameter_sets = [int(i) for i in env['selected_parameter_sets'].split(' ')]

parameter_generator = waves.parameter_generators.CustomStudy(parameter_schema)
for set_name, parameters in parameter_generator.parameter_study_to_dict().items():

    # Optionally skip certain parameter sets
    if parameter_flag == True:
        set = int(str(set_name).split('parameter_set')[-1])
        if set not in selected_parameter_sets:
            continue

    set_name = pathlib.Path(set_name)

    domain_number = parameters['num_domains']
    seed_size = parameters['seed_size']

    filter_results = f"FILTER_RESULTS_{model}_{int(domain_number)}"
    filter_targs = [f"{filter_results}.{ext}" for ext in ['xdmf', 'h5']]
    params['filter_targs'] = filter_targs

    # ---------- FILTER --------------------------------------------------------
    # Run common filter sconscript
    params['update_filter_domains'] = True
    params['homogenize_damage'] = True
    if env['filter']:
        variant_dir = build_directory / set_name
        workflow.extend(
            SConscript("filter.scons", variant_dir=variant_dir,
                       exports=["env", "parameters", "workflow_name", "model", "params", "filter_inputs"],
                       duplicate=False))

    # ---------- CALIBRATE -----------------------------------------------------
    case = params['calibration_case']
    if env['calibrate_elasticity']:
        filter_file = str(build_directory / set_name / filter_targs[0])
        params['filter_file'] = filter_file
        variant_dir = build_directory / set_name
        # Run common calibration sconscript
        workflow.extend(
            SConscript("calibrate_element.scons", variant_dir=variant_dir,
                       exports=["env", "parameters", "workflow_name", "model", "params"],
                       duplicate=False))
    params['calibration_map'] = f'{build_directory}/{set_name}/Calibration_map_elastic_parameters_case_{case}_{domain_number}.csv'

    # ---------- Tardigrade-MOOSE ----------------------------------------------
    # Run common Tardigrade-MOOSE sconscript
    if env['macro']:
        calibration_map = params['calibration_map']
        tardi_sim_name = f'TARDIGRADE-MOOSE_{model}_{domain_number}_elements_calib_case_{case}'
        variant_dir = build_directory / set_name
        workflow.extend(
            SConscript("tardigrade_moose.scons", variant_dir=variant_dir,
                       exports=["env", "parameters", "workflow_name", "model", "params", "tardi_sim_name", "calibration_map"],
                       duplicate=False))
# ---------- Collect Results across Studies ------------------------------------
# Run common post-processing sconscript
if env['summary']:
    study = parameter_generator.parameter_study_to_dict()
    set_names = [pathlib.Path(set_name) for set_name, _ in study.items()]
    num_domains = [str(study[key]['num_domains']) for key in study.keys()]
    dns_forces = f"DNS_{model}_run_force_displacement.csv"

    workflow.extend(
        SConscript("summarize_multi_domain.scons",
                   exports=["env", "workflow_name", "model", "params", "set_names", "num_domains", "dns_forces"],
                   duplicate=False))

# Collector alias based on parent directory name
env.Alias(workflow_name, workflow)
